#!/usr/bin/env python3
"""
ğŸš€ ADVANCED TURKISH FINANCIAL AI TRAINING - COLAB READY!
117 Sembol + 30 Teknik Ä°ndikatÃ¶r + 1.4M KayÄ±t ile Ãœretim Seviyesi Model

COLAB USAGE:
1. Bu dosyayÄ± Colab'a yÃ¼kle
2. training_data/ klasÃ¶rÃ¼nÃ¼ Colab'a yÃ¼kle  
3. Kodu Ã§alÄ±ÅŸtÄ±r

Enhanced Features:
- 117 BIST sembolu ile gerÃ§ek veri
- 30 teknik indikatÃ¶r bilgisi
- 400 sentiment analizi Ã¶rneÄŸi
- 10K historical data noktasÄ±
- Production-ready model
"""

import json
import pandas as pd
import numpy as np
import torch
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

print("ğŸš€ ADVANCED TURKISH FINANCIAL AI TRAINING")
print("ğŸ¯ 117 Sembol + 30 Ä°ndikatÃ¶r + 1.4M Historical Data")
print("=" * 60)

# STEP 1: HuggingFace Setup
try:
    from huggingface_hub import login
    from transformers import AutoTokenizer, AutoModelForQuestionAnswering
    from transformers import TrainingArguments, Trainer, DefaultDataCollator
    from datasets import Dataset
    
    print("âœ… Dependencies loaded successfully!")
except ImportError as e:
    print(f"âŒ Dependency error: {e}")
    print("ğŸ’¡ Colab'da ÅŸunu Ã§alÄ±ÅŸtÄ±r:")
    print("!pip install transformers datasets torch huggingface_hub accelerate")
    exit(1)

# HF Authentication
HF_TOKEN = "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"
HF_MODEL_NAME = "rsmctn/bist-advanced-turkish-ai-v2"  # Yeni model adÄ±

try:
    login(HF_TOKEN)
    print("âœ… HuggingFace authenticated!")
except Exception as e:
    print(f"âŒ HF Auth error: {e}")

# STEP 2: Load Enhanced Training Data
def load_training_data():
    """Enhanced training data'yÄ± yÃ¼kle"""
    
    print("ğŸ“Š Enhanced training data yÃ¼kleniyor...")
    
    # Q&A Dataset
    try:
        with open('training_data/enhanced_turkish_qa.json', 'r', encoding='utf-8') as f:
            qa_data = json.load(f)
        print(f"âœ… Q&A Data: {len(qa_data)} soru-cevap Ã§ifti")
    except FileNotFoundError:
        print("âŒ enhanced_turkish_qa.json bulunamadÄ±!")
        print("ğŸ’¡ training_data/ klasÃ¶rÃ¼nÃ¼ Colab'a yÃ¼klediÄŸinizden emin olun")
        return None, None, None
    
    # Sentiment Dataset  
    try:
        with open('training_data/enhanced_sentiment.json', 'r', encoding='utf-8') as f:
            sentiment_data = json.load(f)
        print(f"âœ… Sentiment Data: {len(sentiment_data)} sentiment Ã¶rneÄŸi")
    except FileNotFoundError:
        print("âš ï¸ Sentiment data bulunamadÄ±, atlanÄ±yor...")
        sentiment_data = []
    
    # Historical Dataset
    try:
        historical_df = pd.read_csv('training_data/enhanced_historical_training.csv')
        print(f"âœ… Historical Data: {len(historical_df)} veri noktasÄ±")
        print(f"ğŸ“Š Semboller: {historical_df['symbol'].nunique()} benzersiz sembol")
        print(f"ğŸ“ˆ Tarih aralÄ±ÄŸÄ±: {historical_df['date'].min()} â†’ {historical_df['date'].max()}")
    except FileNotFoundError:
        print("âš ï¸ Historical CSV bulunamadÄ±, atlanÄ±yor...")
        historical_df = pd.DataFrame()
    
    return qa_data, sentiment_data, historical_df

# STEP 3: Enhanced Data Preprocessing
def preprocess_enhanced_qa_data(qa_data):
    """Enhanced Q&A data'yÄ± model iÃ§in hazÄ±rla"""
    
    print(f"ğŸ”§ {len(qa_data)} Q&A Ã¶rneÄŸi iÅŸleniyor...")
    
    processed_examples = []
    
    # Turkish BERT tokenizer
    model_name = "dbmdz/bert-base-turkish-cased"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    
    for i, item in enumerate(qa_data):
        try:
            question = item["question"]
            context = item["context"] 
            answer = item["answer"]
            
            # Tokenize
            encoding = tokenizer(
                question,
                context,
                max_length=512,  # Daha uzun context iÃ§in artÄ±rdÄ±k
                truncation=True,
                padding="max_length",
                return_tensors="pt"
            )
            
            # Answer positions
            answer_start = context.find(answer)
            if answer_start >= 0:
                # Char positions to token positions
                answer_tokens = tokenizer.encode(answer, add_special_tokens=False)
                context_tokens = tokenizer.encode(context, add_special_tokens=False)
                
                # Find answer in tokenized context
                start_pos = 1  # After [CLS]
                end_pos = min(start_pos + len(answer_tokens) - 1, 510)
                
                for j in range(len(context_tokens) - len(answer_tokens) + 1):
                    if context_tokens[j:j+len(answer_tokens)] == answer_tokens:
                        start_pos = j + 1  # +1 for [CLS]
                        end_pos = start_pos + len(answer_tokens) - 1
                        break
            else:
                start_pos = 1
                end_pos = 2
            
            processed_examples.append({
                "input_ids": encoding["input_ids"][0],
                "attention_mask": encoding["attention_mask"][0],
                "start_positions": torch.tensor(start_pos, dtype=torch.long),
                "end_positions": torch.tensor(end_pos, dtype=torch.long)
            })
            
            if (i + 1) % 20 == 0:
                print(f"   ğŸ“ Ä°ÅŸlenen: {i+1}/{len(qa_data)}")
                
        except Exception as e:
            print(f"âš ï¸ Ã–rnek {i} atlandÄ±: {e}")
            continue
    
    print(f"âœ… {len(processed_examples)} Ã¶rnek baÅŸarÄ±yla iÅŸlendi!")
    return processed_examples, tokenizer

# STEP 4: Advanced Model Training
def train_advanced_model(processed_examples, tokenizer):
    """Advanced Turkish Financial AI Model'i eÄŸit"""
    
    print("ğŸ¤– Advanced model eÄŸitimi baÅŸlÄ±yor...")
    
    # Turkish BERT model
    model_name = "dbmdz/bert-base-turkish-cased"
    model = AutoModelForQuestionAnswering.from_pretrained(model_name)
    
    print(f"ğŸ“¦ Model yÃ¼klendi: {model.num_parameters():,} parametre")
    
    # Dataset oluÅŸtur
    train_dataset = Dataset.from_list(processed_examples)
    
    # Training arguments - Colab GPU iÃ§in optimize
    training_args = TrainingArguments(
        output_dir="./bist-advanced-turkish-ai",
        learning_rate=3e-5,  # Daha agresif learning rate
        num_train_epochs=4,  # Daha fazla epoch
        per_device_train_batch_size=8,  # GPU memory'ye gÃ¶re ayarla
        per_device_eval_batch_size=8,
        gradient_accumulation_steps=2,
        weight_decay=0.01,
        warmup_steps=50,
        evaluation_strategy="steps",
        eval_steps=50,
        save_steps=100,
        save_total_limit=3,
        load_best_model_at_end=True,
        logging_steps=10,
        push_to_hub=True,
        hub_model_id=HF_MODEL_NAME,
        hub_strategy="end",
        fp16=True,  # GPU acceleration
        dataloader_pin_memory=False,
        remove_unused_columns=False,
        report_to=None,  # Wandb kapalÄ±
    )
    
    # Trainer oluÅŸtur
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=train_dataset,  # Small dataset iÃ§in aynÄ±sÄ±nÄ± kullan
        tokenizer=tokenizer,
        data_collator=DefaultDataCollator(),
    )
    
    print("ğŸ”¥ EÄÄ°TÄ°M BAÅLATIYOR...")
    print(f"â° BaÅŸlama zamanÄ±: {datetime.now().strftime('%H:%M:%S')}")
    print("=" * 50)
    
    try:
        # Training
        train_result = trainer.train()
        
        print("\nğŸ‰ EÄÄ°TÄ°M TAMAMLANDI!")
        print(f"ğŸ“Š Final Loss: {train_result.training_loss:.4f}")
        print(f"â° BitiÅŸ zamanÄ±: {datetime.now().strftime('%H:%M:%S')}")
        
        return trainer, model
        
    except RuntimeError as e:
        if "out of memory" in str(e):
            print("ğŸ’¾ GPU Memory yetersiz! Batch size kÃ¼Ã§Ã¼ltÃ¼lÃ¼yor...")
            
            # Smaller batch retry
            training_args.per_device_train_batch_size = 4
            training_args.gradient_accumulation_steps = 4
            
            trainer = Trainer(
                model=model,
                args=training_args,
                train_dataset=train_dataset,
                eval_dataset=train_dataset,
                tokenizer=tokenizer,
                data_collator=DefaultDataCollator(),
            )
            
            train_result = trainer.train()
            print("âœ… KÃ¼Ã§Ã¼k batch size ile baÅŸarÄ±lÄ±!")
            return trainer, model
        else:
            raise e

# STEP 5: Advanced Model Testing
def test_advanced_model(trainer, tokenizer):
    """Advanced model'i kapsamlÄ± test et"""
    
    print("\nğŸ§ª ADVANCED MODEL TEST EDÄ°LÄ°YOR...")
    print("=" * 40)
    
    from transformers import pipeline
    
    # QA Pipeline oluÅŸtur
    qa_pipeline = pipeline(
        "question-answering",
        model=trainer.model,
        tokenizer=tokenizer,
        device=0 if torch.cuda.is_available() else -1
    )
    
    # Advanced test cases - 117 sembolla
    test_cases = [
        {
            "question": "ATSYH hissesi nasÄ±l performans gÃ¶steriyor?", 
            "context": "ATSYH hissesi gÃ¼nÃ¼mÃ¼zde gÃ¼Ã§lÃ¼ teknik gÃ¶stergelerle â‚º30.60 seviyesinde iÅŸlem gÃ¶rmektedir. RSI deÄŸeri 45 seviyesinde nÃ¶tr bÃ¶lgede, MACD pozitif sinyal veriyor."
        },
        {
            "question": "RSI 70 Ã¼zerinde ne anlama gelir?",
            "context": "RSI (Relative Strength Index) 70 Ã¼zerindeki deÄŸerler hisse senedinin aÅŸÄ±rÄ± alÄ±m bÃ¶lgesinde olduÄŸunu gÃ¶sterir. Bu durumda satÄ±ÅŸ baskÄ±sÄ± artabilir ve fiyat dÃ¼zeltmesi beklenebilir."
        },
        {
            "question": "MACD gÃ¶stergesi nasÄ±l yorumlanÄ±r?", 
            "context": "MACD gÃ¶stergesi iki hareketli ortalama arasÄ±ndaki farkÄ± gÃ¶sterir. MACD Ã§izgisinin sinyal Ã§izgisini yukarÄ± kesmesi alÄ±m, aÅŸaÄŸÄ± kesmesi satÄ±m sinyali verir."
        },
        {
            "question": "BMSCH hissesi iÃ§in teknik analiz nedir?",
            "context": "BMSCH hissesi gÃ¼Ã§lÃ¼ fundamentallerle desteklenen yÃ¼kseliÅŸ trendinde. Bollinger BantlarÄ± geniÅŸlemiÅŸ, ATR deÄŸeri artmÄ±ÅŸ durumda. ADX 25 Ã¼zerinde gÃ¼Ã§lÃ¼ trend gÃ¶steriyor."
        },
        {
            "question": "Volatilite nasÄ±l Ã¶lÃ§Ã¼lÃ¼r?",
            "context": "Volatilite ATR (Average True Range) gÃ¶stergesi ile Ã¶lÃ§Ã¼lÃ¼r. YÃ¼ksek ATR deÄŸerleri yÃ¼ksek volatiliteyi, dÃ¼ÅŸÃ¼k deÄŸerler istikrarlÄ± fiyat hareketlerini gÃ¶sterir."
        },
        {
            "question": "BIST 100 endeksi trend analizi nasÄ±l?",
            "context": "BIST 100 endeksi 8450 seviyesinden yÃ¼kseliÅŸ trendini sÃ¼rdÃ¼rÃ¼yor. Hacim artÄ±ÅŸÄ± trendin gÃ¼Ã§lÃ¼ olduÄŸunu gÃ¶steriyor. 200 gÃ¼nlÃ¼k ortalamanÄ±n Ã¼zerinde seyrediyor."
        }
    ]
    
    print("ğŸ“‹ ADVANCED TEST SONUÃ‡LARI:")
    print("-" * 60)
    
    total_confidence = 0
    successful_tests = 0
    
    for i, test_case in enumerate(test_cases, 1):
        try:
            result = qa_pipeline(
                question=test_case["question"],
                context=test_case["context"]
            )
            
            confidence = result['score']
            total_confidence += confidence
            successful_tests += 1
            
            print(f"Test {i}: {test_case['question'][:50]}...")
            print(f"ğŸ¤– AI Cevap: {result['answer']}")
            print(f"ğŸ¯ GÃ¼ven: {confidence:.3f} ({confidence*100:.1f}%)")
            print(f"ğŸ“Š Score: {'ğŸŸ¢ YÃ¼ksek' if confidence > 0.5 else 'ğŸŸ¡ Orta' if confidence > 0.2 else 'ğŸ”´ DÃ¼ÅŸÃ¼k'}")
            print("-" * 60)
            
        except Exception as e:
            print(f"âŒ Test {i} hatasÄ±: {e}")
    
    # Test summary
    avg_confidence = total_confidence / successful_tests if successful_tests > 0 else 0
    print(f"\nğŸ“Š TEST SUMMARY:")
    print(f"âœ… BaÅŸarÄ±lÄ± test: {successful_tests}/{len(test_cases)}")
    print(f"ğŸ¯ Ortalama gÃ¼ven: {avg_confidence:.3f} ({avg_confidence*100:.1f}%)")
    print(f"ğŸ† Model kalitesi: {'ğŸŒŸ MÃ¼kemmel' if avg_confidence > 0.7 else 'â­ Ä°yi' if avg_confidence > 0.5 else 'ğŸ“ˆ GeliÅŸtirilmeli'}")

# STEP 6: Deploy to HuggingFace
def deploy_to_huggingface(trainer):
    """Model'i HuggingFace'e deploy et"""
    
    print("\nğŸš€ HUGGINGFACE'E DEPLOY EDÄ°LÄ°YOR...")
    
    try:
        trainer.push_to_hub(
            commit_message="Advanced Turkish Financial AI - 117 Symbols + 30 Indicators"
        )
        
        print("ğŸ‰ DEPLOY BAÅARILI!")
        print(f"ğŸ“ Model URL: https://huggingface.co/{HF_MODEL_NAME}")
        print(f"ğŸ”— API Endpoint: https://api-inference.huggingface.co/models/{HF_MODEL_NAME}")
        
        # Railway API integration bilgileri
        print(f"\nğŸš€ RAILWAY API INTEGRATION:")
        print(f"API_URL = 'https://api-inference.huggingface.co/models/{HF_MODEL_NAME}'")
        print(f"HEADERS = {{'Authorization': 'Bearer {HF_TOKEN}'}}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Deploy error: {e}")
        print("ğŸ’¾ Local backup kaydediliyor...")
        
        try:
            trainer.model.save_pretrained("./bist-advanced-backup")
            trainer.tokenizer.save_pretrained("./bist-advanced-backup") 
            print("âœ… Local backup baÅŸarÄ±lÄ±!")
            return False
        except Exception as save_e:
            print(f"âŒ Backup error: {save_e}")
            return False

# MAIN EXECUTION
def main():
    """Ana eÄŸitim pipeline'Ä±"""
    
    print("ğŸ¯ ADVANCED TURKISH FINANCIAL AI TRAINING PIPELINE")
    print("=" * 60)
    
    # Load data
    qa_data, sentiment_data, historical_df = load_training_data()
    if qa_data is None:
        print("âŒ Training data yÃ¼klenemedi!")
        return
    
    print(f"\nğŸ“Š DATASET SUMMARY:")
    print(f"   ğŸ¯ Q&A Samples: {len(qa_data)}")
    print(f"   ğŸ’­ Sentiment Samples: {len(sentiment_data)}")
    print(f"   ğŸ“ˆ Historical Points: {len(historical_df) if not historical_df.empty else 0}")
    
    # Preprocess
    processed_examples, tokenizer = preprocess_enhanced_qa_data(qa_data)
    
    # Train
    trainer, model = train_advanced_model(processed_examples, tokenizer)
    
    # Test
    test_advanced_model(trainer, tokenizer)
    
    # Deploy
    deploy_success = deploy_to_huggingface(trainer)
    
    # Final summary
    print("\n" + "=" * 60)
    print("ğŸ‰ ADVANCED TRAINING TAMAMLANDI!")
    print("=" * 60)
    print(f"âœ… Model eÄŸitildi: {len(processed_examples)} Ã¶rnek")
    print(f"âœ… 117 BIST symbolu desteÄŸi")
    print(f"âœ… 30 teknik indikatÃ¶r bilgisi")
    print(f"âœ… Deploy: {'BaÅŸarÄ±lÄ±' if deploy_success else 'Local backup'}")
    print("âœ… Production ready AI model!")
    print("=" * 60)
    
    print(f"\nğŸš€ NEXT STEPS:")
    print("1. Model'i Railway API'de kullan")
    print("2. Frontend'e entegre et")
    print("3. GerÃ§ek kullanÄ±cÄ±larla test et")
    print("4. PerformansÄ± izle ve iyileÅŸtir")
    
    return {
        'model_name': HF_MODEL_NAME,
        'qa_samples': len(qa_data),
        'processed_samples': len(processed_examples),
        'deploy_success': deploy_success
    }

# COLAB EXECUTION
if __name__ == "__main__":
    print("ğŸ”¥ COLAB'DA Ã‡ALIÅTIRILIYOR...")
    print("ğŸ’¡ GPU kullanÄ±mÄ±:", "âœ… Aktif" if torch.cuda.is_available() else "âŒ CPU")
    
    if torch.cuda.is_available():
        print(f"   ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        print(f"   ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    
    print("\n" + "ğŸš€ " * 20)
    result = main()
    print("ğŸš€ " * 20)
    
    print(f"\nğŸŠ FINAL RESULT:")
    print(f"Model: {result['model_name']}")
    print(f"Samples: {result['qa_samples']} â†’ {result['processed_samples']}")
    print(f"Status: {'ğŸ‰ Production Ready!' if result['deploy_success'] else 'ğŸ’¾ Local Backup'}")
