"""
Turkish VADER Sentiment Analysis Adapter
Optimized for Financial/Stock Market Sentiment Analysis
"""

import re
from typing import Dict, List, Optional, Tuple, Any
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import logging


class TurkishVaderAnalyzer:
    """
    Turkish adaptation of VADER Sentiment Analysis
    Specifically tuned for financial/stock market sentiment
    """
    
    def __init__(self):
        self.analyzer = SentimentIntensityAnalyzer()
        self.logger = logging.getLogger(__name__)
        
        # Turkish financial sentiment lexicon
        self.turkish_financial_lexicon = self._build_turkish_financial_lexicon()
        
        # Turkish linguistic features
        self.turkish_intensifiers = self._build_turkish_intensifiers()
        self.turkish_negations = self._build_turkish_negations()
        
        # Company name patterns for BIST
        self.bist_companies = self._build_bist_company_patterns()
        
        # Update VADER lexicon with Turkish terms
        self._update_vader_lexicon()
        
        self.logger.info("Turkish VADER Analyzer initialized")
    
    def _build_turkish_financial_lexicon(self) -> Dict[str, float]:
        """Build Turkish financial sentiment dictionary"""
        return {
            # Positive financial terms
            'yÃ¼kseliÅŸ': 2.5, 'artÄ±ÅŸ': 2.0, 'bÃ¼yÃ¼me': 2.2, 'kÃ¢r': 2.8, 'kazanÃ§': 2.5,
            'gelir': 1.8, 'baÅŸarÄ±': 2.3, 'gÃ¼Ã§lÃ¼': 2.0, 'saÄŸlam': 1.9, 'istikrarlÄ±': 1.7,
            'pozitif': 2.1, 'olumlu': 2.0, 'iyi': 1.5, 'mÃ¼kemmel': 2.8, 'harika': 2.5,
            'yÃ¼ksek': 1.8, 'artan': 1.9, 'Ã§Ä±kÄ±ÅŸ': 1.6, 'rekor': 2.4, 'maksimum': 2.0,
            'patlama': 2.2, 'sÄ±Ã§rama': 2.3, 'yÃ¼kselme': 2.1, 'tÄ±rmanÄ±ÅŸ': 2.0,
            'geniÅŸleme': 1.8, 'iyileÅŸme': 2.0, 'toparlanma': 2.1, 'canlanma': 2.2,
            'gÃ¼ven': 1.9, 'umut': 1.7, 'fÄ±rsat': 1.8, 'potansiyel': 1.6,
            'verimli': 1.9, 'karlÄ±': 2.3, 'baÅŸarÄ±lÄ±': 2.1, 'etkili': 1.8,
            
            # Negative financial terms
            'dÃ¼ÅŸÃ¼ÅŸ': -2.5, 'azalÄ±ÅŸ': -2.0, 'kÃ¼Ã§Ã¼lme': -2.2, 'zarar': -2.8, 'kayÄ±p': -2.5,
            'gerileme': -2.1, 'baÅŸarÄ±sÄ±zlÄ±k': -2.3, 'zayÄ±f': -2.0, 'kÄ±rÄ±lgan': -1.9,
            'istikrarsÄ±z': -2.2, 'negatif': -2.1, 'olumsuz': -2.0, 'kÃ¶tÃ¼': -1.8,
            'berbat': -2.8, 'feci': -2.5, 'dÃ¼ÅŸÃ¼k': -1.8, 'azalan': -1.9, 'iniÅŸ': -1.6,
            'minimum': -2.0, 'Ã§Ã¶kÃ¼ÅŸ': -2.8, 'dÃ¼ÅŸme': -2.1, 'gerileme': -2.0,
            'daralma': -2.2, 'kÃ¶tÃ¼leÅŸme': -2.3, 'bozulma': -2.1, 'Ã§Ã¶zÃ¼lme': -2.0,
            'endiÅŸe': -1.9, 'korku': -2.2, 'panik': -2.5, 'kriz': -2.8,
            'verimsiz': -1.9, 'zararlÄ±': -2.3, 'baÅŸarÄ±sÄ±z': -2.1, 'etkisiz': -1.8,
            'tehlike': -2.4, 'risk': -1.8, 'belirsizlik': -1.7, 'sorun': -1.9,
            
            # Market specific terms
            'boÄŸa': 2.5, 'ayÄ±': -2.5, 'rallisi': 2.3, 'satÄ±ÅŸ': -1.5, 'alÄ±m': 1.8,
            'hacim': 1.2, 'likidite': 1.5, 'volatilite': -1.2, 'manipÃ¼lasyon': -2.5,
            'spekÃ¼lasyon': -1.8, 'investisyon': 1.9, 'yatÄ±rÄ±m': 1.7, 'portfÃ¶y': 1.2,
            'hisse': 1.0, 'borsa': 1.1, 'endeks': 1.0, 'piyasa': 0.8,
            
            # Intensifiers in Turkish context
            'Ã§ok': 0.8, 'oldukÃ§a': 0.6, 'son derece': 1.0, 'fevkalade': 1.2,
            'kesinlikle': 0.9, 'mutlaka': 0.7, 'gerÃ§ekten': 0.8, 'Ã¶zellikle': 0.6,
            'bÃ¼yÃ¼k': 0.7, 'kÃ¼Ã§Ã¼k': -0.5, 'hafif': -0.3, 'ÅŸiddetli': 0.9,
            
            # Banking specific terms
            'kredi': 0.5, 'faiz': -0.8, 'enflasyon': -1.5, 'deflasyon': -1.2,
            'devalÃ¼asyon': -2.0, 'revalÃ¼asyon': 1.8, 'dolar': 0.2, 'euro': 0.2,
            'merkez bankasÄ±': 0.5, 'politika': 0.3, 'karar': 0.8, 'aÃ§Ä±klama': 0.5,
        }
    
    def _build_turkish_intensifiers(self) -> Dict[str, float]:
        """Turkish intensifier words"""
        return {
            'Ã§ok': 0.293, 'oldukÃ§a': 0.293, 'son derece': 0.457, 'fevkalade': 0.596,
            'kesinlikle': 0.293, 'mutlaka': 0.293, 'gerÃ§ekten': 0.293, 'Ã¶zellikle': 0.293,
            'bÃ¼yÃ¼k Ã¶lÃ§Ã¼de': 0.457, 'tamamen': 0.596, 'tÃ¼mÃ¼yle': 0.596, 'bÃ¼tÃ¼nÃ¼yle': 0.596,
            'aÅŸÄ±rÄ±': 0.596, 'ultra': 0.596, 'sÃ¼per': 0.596, 'mega': 0.596,
            'maksimum': 0.596, 'minimum': -0.596, 'az': -0.293, 'biraz': -0.293,
        }
    
    def _build_turkish_negations(self) -> List[str]:
        """Turkish negation words"""
        return [
            'deÄŸil', 'deÄŸildir', 'olmayan', 'olmamÄ±ÅŸ', 'deÄŸilmiÅŸ', 'deÄŸilse',
            'hayÄ±r', 'yok', 'yoktur', 'yoxdur', 'asla', 'hiÃ§', 'hiÃ§bir',
            'ne', 'nerede', 'nasÄ±l', 'niÃ§in', 'niye', 'neden',
            'mÃ¼mkÃ¼n deÄŸil', 'imkansÄ±z', 'olamaz', 'olmaz',
            'karÅŸÄ±', 'karÅŸÄ±t', 'ters', 'zÄ±t', 'aksi',
            'red', 'reddediyor', 'reddetti', 'ret',
        ]
    
    def _build_bist_company_patterns(self) -> Dict[str, List[str]]:
        """BIST company name patterns for entity recognition"""
        return {
            # Major BIST companies and their variants
            'AKBNK': ['akbank', 'ak bank', 'ak bankasÄ±', 'akbankasÄ±'],
            'GARAN': ['garanti', 'garanti bankasÄ±', 'tgb', 'tÃ¼rkiye garanti bankasÄ±'],
            'ISCTR': ['iÅŸbank', 'iÅŸ bankasÄ±', 'tÃ¼rkiye iÅŸ bankasÄ±', 'iÅŸbankasÄ±'],
            'YKBNK': ['yapÄ± kredi', 'yapÄ± kredi bankasÄ±', 'ykb', 'yapÄ±kredi'],
            'HALKB': ['halkbank', 'halk bankasÄ±', 'tÃ¼rkiye halk bankasÄ±'],
            'VAKBN': ['vakÄ±fbank', 'vakÄ±f bankasÄ±', 'vakÄ±f bank'],
            'SISE': ['ÅŸiÅŸe cam', 'ÅŸiÅŸecam', 'tÃ¼rkiye ÅŸiÅŸe ve cam'],
            'THYAO': ['thy', 'tÃ¼rk hava yollarÄ±', 'turkish airlines'],
            'BIMAS': ['bim', 'birleÅŸik maÄŸazalar'],
            'MGROS': ['migros', 'migros ticaret'],
            'CCOLA': ['coca cola', 'koka kola', 'coca-cola'],
            'PETKM': ['petkim', 'petrokimya'],
            'TUPRS': ['tÃ¼praÅŸ', 'tÃ¼rkiye petrol rafinerileri'],
            'KRDMD': ['kardemir', 'karabÃ¼k demir Ã§elik'],
            'EREGL': ['erdemir', 'ereÄŸli demir Ã§elik'],
            'ARCLK': ['arÃ§elik', 'koÃ§ arÃ§elik'],
            'VESTL': ['vestel', 'vestel elektronik'],
            'TTKOM': ['tÃ¼rk telekom', 'tÃ¼rktelekom', 'tt'],
            'TCELL': ['turkcell', 'tÃ¼rk cell', 'turk cell'],
            # Add more as needed...
        }
    
    def _update_vader_lexicon(self):
        """Update VADER's lexicon with Turkish financial terms"""
        for word, score in self.turkish_financial_lexicon.items():
            self.analyzer.lexicon[word.lower()] = score
            
        self.logger.info(f"Updated VADER lexicon with {len(self.turkish_financial_lexicon)} Turkish terms")
    
    def preprocess_turkish_text(self, text: str) -> str:
        """Preprocess Turkish text for better sentiment analysis"""
        if not text:
            return ""
        
        # Convert to lowercase
        text = text.lower()
        
        # Turkish character normalization
        turkish_chars = {
            'Ã§': 'c', 'ÄŸ': 'g', 'Ä±': 'i', 'Ã¶': 'o', 'ÅŸ': 's', 'Ã¼': 'u',
            # Keep original Turkish chars too for lexicon matching
        }
        
        # Clean extra whitespace
        text = re.sub(r'\s+', ' ', text.strip())
        
        # Handle Turkish punctuation
        text = re.sub(r'[!]{2,}', '!', text)  # Multiple exclamations
        text = re.sub(r'[?]{2,}', '?', text)  # Multiple questions
        
        return text
    
    def extract_company_entities(self, text: str) -> List[Tuple[str, str]]:
        """Extract BIST company mentions from text"""
        entities = []
        text_lower = text.lower()
        
        for symbol, variants in self.bist_companies.items():
            for variant in variants:
                if variant in text_lower:
                    # Find actual position for context
                    start_pos = text_lower.find(variant)
                    entities.append((symbol, variant))
        
        return list(set(entities))  # Remove duplicates
    
    def analyze_sentiment(self, text: str, consider_entities: bool = True) -> Dict[str, Any]:
        """
        Analyze sentiment of Turkish text with financial context
        
        Args:
            text: Input text to analyze
            consider_entities: Whether to boost/modify sentiment based on entity mentions
            
        Returns:
            Dictionary with sentiment scores and metadata
        """
        if not text or not text.strip():
            return {
                'compound': 0.0,
                'pos': 0.0,
                'neu': 1.0,
                'neg': 0.0,
                'confidence': 0.0,
                'entities': [],
                'processed_text': '',
                'language': 'tr'
            }
        
        # Preprocess text
        processed_text = self.preprocess_turkish_text(text)
        
        # Extract company entities
        entities = []
        if consider_entities:
            entities = self.extract_company_entities(text)
        
        # Get base VADER scores
        vader_scores = self.analyzer.polarity_scores(processed_text)
        
        # Adjust scores based on Turkish linguistic features
        adjusted_scores = self._adjust_for_turkish_features(
            processed_text, vader_scores, entities
        )
        
        # Calculate confidence score
        confidence = self._calculate_confidence(adjusted_scores, len(entities))
        
        return {
            'compound': adjusted_scores['compound'],
            'pos': adjusted_scores['pos'],
            'neu': adjusted_scores['neu'],
            'neg': adjusted_scores['neg'],
            'confidence': confidence,
            'entities': entities,
            'processed_text': processed_text,
            'language': 'tr'
        }
    
    def _adjust_for_turkish_features(self, text: str, scores: Dict[str, float], 
                                   entities: List[Tuple[str, str]]) -> Dict[str, float]:
        """Adjust sentiment scores for Turkish linguistic features"""
        
        adjusted = scores.copy()
        
        # Boost sentiment if financial entities are mentioned
        if entities:
            entity_boost = min(0.1 * len(entities), 0.3)  # Max 30% boost
            
            if adjusted['compound'] > 0:
                adjusted['compound'] = min(1.0, adjusted['compound'] + entity_boost)
                adjusted['pos'] = min(1.0, adjusted['pos'] + entity_boost * 0.5)
            elif adjusted['compound'] < 0:
                adjusted['compound'] = max(-1.0, adjusted['compound'] - entity_boost)
                adjusted['neg'] = min(1.0, adjusted['neg'] + entity_boost * 0.5)
        
        # Turkish intensifier patterns
        intensifier_pattern = r'\b(Ã§ok|son derece|oldukÃ§a|kesinlikle)\s+(\w+)'
        intensifiers = re.findall(intensifier_pattern, text)
        
        if intensifiers:
            intensifier_boost = len(intensifiers) * 0.05  # Small boost per intensifier
            if adjusted['compound'] > 0:
                adjusted['compound'] = min(1.0, adjusted['compound'] + intensifier_boost)
            elif adjusted['compound'] < 0:
                adjusted['compound'] = max(-1.0, adjusted['compound'] - intensifier_boost)
        
        # Turkish negation handling - more sophisticated
        negation_words = self.turkish_negations
        for neg_word in negation_words:
            if neg_word in text:
                # Flip sentiment if strong negation detected
                if abs(adjusted['compound']) > 0.1:  # Only if there's clear sentiment
                    adjusted['compound'] *= -0.8  # Partial reversal, not complete
                    # Swap pos/neg scores
                    adjusted['pos'], adjusted['neg'] = adjusted['neg'] * 0.8, adjusted['pos'] * 0.8
                break
        
        # Ensure scores are normalized
        total = adjusted['pos'] + adjusted['neu'] + adjusted['neg']
        if total > 0:
            adjusted['pos'] /= total
            adjusted['neu'] /= total
            adjusted['neg'] /= total
        
        return adjusted
    
    def _calculate_confidence(self, scores: Dict[str, float], entity_count: int) -> float:
        """Calculate confidence score for the sentiment analysis"""
        
        # Base confidence from compound score strength
        base_confidence = abs(scores['compound'])
        
        # Boost confidence if entities are mentioned (more context)
        entity_boost = min(entity_count * 0.1, 0.2)
        
        # Boost confidence if sentiment is clear (not neutral)
        clarity_boost = 0.0
        if scores['pos'] > 0.6 or scores['neg'] > 0.6:
            clarity_boost = 0.1
        elif scores['neu'] > 0.8:  # Very neutral
            base_confidence *= 0.7
        
        confidence = min(1.0, base_confidence + entity_boost + clarity_boost)
        return round(confidence, 3)
    
    def analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """Analyze sentiment for multiple texts"""
        results = []
        
        for text in texts:
            try:
                result = self.analyze_sentiment(text)
                results.append(result)
            except Exception as e:
                self.logger.error(f"Error analyzing text: {str(e)}")
                results.append({
                    'compound': 0.0, 'pos': 0.0, 'neu': 1.0, 'neg': 0.0,
                    'confidence': 0.0, 'entities': [], 'error': str(e)
                })
        
        return results


def test_turkish_vader():
    """Test function for Turkish VADER analyzer"""
    
    analyzer = TurkishVaderAnalyzer()
    
    test_sentences = [
        "Akbank hisseleri bugÃ¼n %5 yÃ¼kseldi, Ã§ok gÃ¼Ã§lÃ¼ performans!",
        "Garanti BankasÄ±'nÄ±n kÃ¢rlarÄ± dÃ¼ÅŸtÃ¼, yatÄ±rÄ±mcÄ±lar endiÅŸeli",
        "BIST 100 endeksi rekor kÄ±rdÄ±, boÄŸa piyasasÄ± devam ediyor",
        "TÃ¼rk Telekom'un hisseleri Ã§ok kÃ¶tÃ¼ performans gÃ¶steriyor, bÃ¼yÃ¼k zarar",
        "Piyasalar pozitif, tÃ¼m bankacÄ±lÄ±k hisseleri yÃ¼kseliÅŸte",
        "Ekonomik belirsizlik artÄ±yor, yatÄ±rÄ±mcÄ±lar temkinli",
        "THY hisselerinde muhteÅŸem artÄ±ÅŸ, rekor kÄ±rÄ±yor!",
        "Bim'in satÄ±ÅŸlarÄ± Ã§ok iyi, mÃ¼thiÅŸ bÃ¼yÃ¼me",
        "Kredi faizleri yÃ¼kseldi, bankalar iÃ§in olumsuz haber deÄŸil"
    ]
    
    print("ğŸ§  Turkish VADER Sentiment Analysis Test")
    print("=" * 60)
    
    for i, sentence in enumerate(test_sentences, 1):
        result = analyzer.analyze_sentiment(sentence)
        
        print(f"\n{i}. Text: {sentence}")
        print(f"   Compound: {result['compound']:.3f}")
        print(f"   Pos: {result['pos']:.3f}, Neu: {result['neu']:.3f}, Neg: {result['neg']:.3f}")
        print(f"   Confidence: {result['confidence']:.3f}")
        if result['entities']:
            print(f"   Entities: {result['entities']}")
    
    print("\nâœ… Turkish VADER test completed!")


if __name__ == "__main__":
    test_turkish_vader()
